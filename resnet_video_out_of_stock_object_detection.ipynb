{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5FNuiRPWKMN"
   },
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bm0_uNRnWKMN"
   },
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VyPz_t8WWKMQ"
   },
   "outputs": [],
   "source": [
    "# # List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = r'C:\\Users\\krish\\Documents\\tensorflow\\workspace\\training_demo_resnet_2k\\annotations\\label_map.pbtxt'\n",
    "PATH_TO_FROZEN_GRAPH = r'C:\\Users\\krish\\Documents\\tensorflow\\workspace\\training_demo_resnet_2k\\trained-inference-graphs\\output_inference_graph_v1\\frozen_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\krish\\AppData\\Local\\Temp\\ipykernel_23160\\469708683.py:3: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\krish\\AppData\\Local\\Temp\\ipykernel_23160\\469708683.py:4: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r\"C:\\Users\\krish\\Desktop\\images\\freshco_video.mp4\")\n",
    "# Detection\n",
    "centers = []\n",
    "c=1\n",
    "# Detection\n",
    "with detection_graph.as_default():\n",
    "    with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "        while True:\n",
    "            # Read frame from camera\n",
    "            ret, image_np = cap.read()\n",
    "            if c%5==0 and ret == True:\n",
    "                image_np = cv2.rotate(image_np,cv2.ROTATE_90_CLOCKWISE)\n",
    "                im_width = image_np.shape[1]\n",
    "                im_height = image_np.shape[0]\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                # Extract image tensor\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                # Extract detection boxes\n",
    "                boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                # Extract detection scores\n",
    "                scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                # Extract detection classes\n",
    "                classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                # Extract number of detectionsd\n",
    "                num_detections = detection_graph.get_tensor_by_name(\n",
    "                    'num_detections:0')\n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "                min_score_thresh = 0.5\n",
    "                for i in range(boxes.shape[1]):\n",
    "                    if scores is None or scores[0][i] > min_score_thresh:\n",
    "                        # boxes[i] is the box which will be drawn\n",
    "                        center_x = int(((boxes[0][i][1]+boxes[0][i][3])/2)*im_width)\n",
    "                        center_y = int(((boxes[0][i][0]+boxes[0][i][2])/2)*im_height)\n",
    "                        centers.append([center_x,center_y])\n",
    "                        \n",
    "\n",
    "                # Visualization of the results of a detection.\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    image_np,\n",
    "                    np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=8)\n",
    "\n",
    "                # Display output\n",
    "                cv2.imshow('object detection',image_np)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            elif ret == False:\n",
    "                break\n",
    "            c = c+1\n",
    "        cap.release()\n",
    "        # Destroy all the windows\n",
    "        cv2.destroyAllWindows()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save prediction as video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r\"C:\\Users\\krish\\Desktop\\images\\freshco_video.mp4\")\n",
    "out = cv2.VideoWriter(r'C:\\Users\\krish\\Desktop\\output1.mp4', -1, 20, (720,1280))\n",
    "c=1\n",
    "\n",
    "# Detection\n",
    "with detection_graph.as_default():\n",
    "    with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "        while True:\n",
    "            # Read frame from camera\n",
    "            ret, image_np = cap.read()\n",
    "            if c%5==0 and ret == True:\n",
    "                image_np = cv2.rotate(image_np,cv2.ROTATE_90_CLOCKWISE)\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                # Extract image tensor\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                # Extract detection boxes\n",
    "                boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                # Extract detection scores\n",
    "                scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                # Extract detection classes\n",
    "                classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                # Extract number of detectionsd\n",
    "                num_detections = detection_graph.get_tensor_by_name(\n",
    "                    'num_detections:0')\n",
    "                \n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "                \n",
    "                min_score_thresh = 0.5\n",
    "                for i in range(boxes.shape[1]):\n",
    "                    if scores is None or scores[0][i] > min_score_thresh:\n",
    "                        # boxes[i] is the box which will be drawn\n",
    "                        center_x = int(((boxes[0][i][1]+boxes[0][i][3])/2)*im_width)\n",
    "                        center_y = int(((boxes[0][i][0]+boxes[0][i][2])/2)*im_height)\n",
    "                        centers.append([center_x,center_y])\n",
    "                \n",
    "                # Visualization of the results of a detection.\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    image_np,\n",
    "                    np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=8)\n",
    "                \n",
    "                \n",
    "                # Display output\n",
    "                out.write(image_np)\n",
    "            \n",
    "            elif ret == False:\n",
    "                break\n",
    "            c = c+1\n",
    "        cap.release()\n",
    "        out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect with database and fetch out of stock items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LQSEnEsPWKMj"
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client[\"AI_PROJ\"]\n",
    "collect = db[\"shelfod_video\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_out_of_shelf = set(())\n",
    "\n",
    "for [center_x, center_y] in centers:\n",
    "    result = collect.find({\n",
    "        \"$and\":[\n",
    "    {\"xmin\" : { \"$lt\" : center_x}},\n",
    "    {\"ymin\" : { \"$lt\" : center_y}},\n",
    "    {\"xmax\" : { \"$gt\" : center_x}},\n",
    "    {\"ymax\" : { \"$gt\" : center_y}}\n",
    "    ]})\n",
    "    for i in result:\n",
    "        items_out_of_shelf.add(i[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compliments_berrys', 'silk_almond', 'earths_own_oat_original', 'almond_breeze_orginal', 'earths_own_barista', 'almond_breeze_chocolate', 'zevia_ginger'}\n"
     ]
    }
   ],
   "source": [
    "print(items_out_of_shelf)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "test3",
   "language": "python",
   "name": "test3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
